"""
Direct LLM Strands Tools Test
ç›´æ¥æµ‹è¯• LLM è°ƒç”¨ Strands Tools çš„è„šæœ¬
"""
import sys
import os
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio
from genai.agents.provider import AgentProvider
from genai.tools.provider import tool_provider


async def test_llm_with_strands_tools():
    """ç›´æ¥æµ‹è¯• LLM è°ƒç”¨ Strands å·¥å…·"""
    print("ğŸ¤– å¼€å§‹æµ‹è¯• LLM ç›´æ¥è°ƒç”¨ Strands Tools...")
    
    try:
        # 1. è·å– Strands å·¥å…·
        print("\nğŸ“¦ è·å– Strands å·¥å…·...")
        tools = await tool_provider.get_tools_for_agent(
            include_legacy=False,
            include_mcp=False,
            include_strands=True,
            tool_filter=['current_time', 'calculator', 'http_request']
        )
        
        print(f"âœ… æˆåŠŸè·å– {len(tools)} ä¸ª Strands å·¥å…·")
        
        # 2. åˆ›å»º AgentProvider
        print("\nğŸ§  åˆ›å»º AgentProvider...")
        system_prompt = """You are a helpful assistant with access to tools. 
        Use the appropriate tools to answer user questions accurately.
        Always use tools when they can help provide better answers."""
        
        agent_provider = AgentProvider(
            model_id="anthropic.claude-3-5-sonnet-20241022-v2:0",
            system_prompt=system_prompt
        )
        print("âœ… AgentProvider åˆ›å»ºæˆåŠŸ")
        
        # 3. é…ç½®å·¥å…·
        tool_config = {
            'enabled': True,
            'include_legacy': False,
            'include_mcp': False,
            'include_strands': True,
            'tool_filter': ['current_time', 'calculator', 'http_request']
        }
        
        # 4. æµ‹è¯•æ—¶é—´å·¥å…·
        print("\nâ° æµ‹è¯• current_time å·¥å…·...")
        try:
            response_chunks = []
            async for chunk in agent_provider.generate_stream(
                "What time is it now? Please use the current_time tool.", 
                tool_config
            ):
                response_chunks.append(chunk)
                # é™åˆ¶å“åº”æ•°é‡
                if len(response_chunks) > 20:
                    break
            
            # åˆå¹¶å“åº”
            full_response = ""
            for chunk in response_chunks:
                if isinstance(chunk, dict) and 'content' in chunk:
                    if 'text' in chunk['content']:
                        full_response += chunk['content']['text']
            
            print(f"ğŸ• æ—¶é—´æŸ¥è¯¢å“åº”: {full_response[:200]}...")
            
        except Exception as e:
            print(f"âŒ æ—¶é—´å·¥å…·æµ‹è¯•å¤±è´¥: {e}")
        
        # 5. æµ‹è¯•è®¡ç®—å™¨å·¥å…·
        print("\nğŸ§® æµ‹è¯• calculator å·¥å…·...")
        try:
            response_chunks = []
            async for chunk in agent_provider.generate_stream(
                "Please calculate 25 * 17 using the calculator tool.", 
                tool_config
            ):
                response_chunks.append(chunk)
                if len(response_chunks) > 20:
                    break
            
            # åˆå¹¶å“åº”
            full_response = ""
            for chunk in response_chunks:
                if isinstance(chunk, dict) and 'content' in chunk:
                    if 'text' in chunk['content']:
                        full_response += chunk['content']['text']
            
            print(f"ğŸ”¢ è®¡ç®—å“åº”: {full_response[:200]}...")
            
        except Exception as e:
            print(f"âŒ è®¡ç®—å™¨å·¥å…·æµ‹è¯•å¤±è´¥: {e}")
        
        # 6. æµ‹è¯• HTTP è¯·æ±‚å·¥å…·
        print("\nğŸŒ æµ‹è¯• http_request å·¥å…·...")
        try:
            response_chunks = []
            async for chunk in agent_provider.generate_stream(
                "Make a GET request to https://httpbin.org/json using the http_request tool.", 
                tool_config
            ):
                response_chunks.append(chunk)
                if len(response_chunks) > 20:
                    break
            
            # åˆå¹¶å“åº”
            full_response = ""
            for chunk in response_chunks:
                if isinstance(chunk, dict) and 'content' in chunk:
                    if 'text' in chunk['content']:
                        full_response += chunk['content']['text']
            
            print(f"ğŸ“¡ HTTP è¯·æ±‚å“åº”: {full_response[:200]}...")
            
        except Exception as e:
            print(f"âŒ HTTP å·¥å…·æµ‹è¯•å¤±è´¥: {e}")
        
        print("\nğŸ‰ æ‰€æœ‰åŸºç¡€å·¥å…·æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


async def test_llm_with_media_tools():
    """æµ‹è¯• LLM è°ƒç”¨åª’ä½“å·¥å…·"""
    print("\nğŸ¨ å¼€å§‹æµ‹è¯• LLM è°ƒç”¨åª’ä½“å·¥å…·...")
    
    try:
        # è·å–åª’ä½“å·¥å…·
        print("\nğŸ“¦ è·å–åª’ä½“å·¥å…·...")
        tools = await tool_provider.get_tools_for_agent(
            include_legacy=False,
            include_mcp=False,
            include_strands=True,
            tool_filter=['generate_image', 'speak']  # å…ˆæµ‹è¯•è¿™ä¸¤ä¸ª
        )
        
        print(f"âœ… æˆåŠŸè·å– {len(tools)} ä¸ªåª’ä½“å·¥å…·")
        
        if len(tools) == 0:
            print("âš ï¸ æ²¡æœ‰å¯ç”¨çš„åª’ä½“å·¥å…·ï¼Œè·³è¿‡åª’ä½“æµ‹è¯•")
            return
        
        # åˆ›å»ºä¸“é—¨çš„åª’ä½“ Agent
        print("\nğŸ­ åˆ›å»ºåª’ä½“ Agent...")
        media_agent = Agent(
            system_prompt="""You are a creative assistant with access to media generation tools.
            When asked to create images, use the generate_image tool.
            When asked to create audio or speech, use the speak tool.
            Always try to use the appropriate tools for media creation requests.""",
            tools=tools
        )
        print("âœ… åª’ä½“ Agent åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•å›¾åƒç”Ÿæˆå·¥å…·
        print("\nğŸ–¼ï¸ æµ‹è¯• generate_image å·¥å…·...")
        try:
            response = media_agent("Please generate an image of a beautiful sunset over the ocean.")
            print(f"ğŸ¨ å›¾åƒç”Ÿæˆå“åº”: {response}")
        except Exception as e:
            print(f"âŒ å›¾åƒç”Ÿæˆå·¥å…·æµ‹è¯•å¤±è´¥: {e}")
        
        # æµ‹è¯•è¯­éŸ³å·¥å…·
        print("\nğŸ”Š æµ‹è¯• speak å·¥å…·...")
        try:
            response = media_agent("Please generate speech saying 'Hello, this is a test of the speak tool.'")
            print(f"ğŸ™ï¸ è¯­éŸ³ç”Ÿæˆå“åº”: {response}")
        except Exception as e:
            print(f"âŒ è¯­éŸ³å·¥å…·æµ‹è¯•å¤±è´¥: {e}")
        
        print("\nğŸ‰ åª’ä½“å·¥å…·æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ åª’ä½“å·¥å…·æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


async def test_llm_complex_task():
    """æµ‹è¯• LLM æ‰§è¡Œå¤æ‚ä»»åŠ¡ï¼ˆä½¿ç”¨å¤šä¸ªå·¥å…·ï¼‰"""
    print("\nğŸš€ å¼€å§‹æµ‹è¯• LLM æ‰§è¡Œå¤æ‚ä»»åŠ¡...")
    
    try:
        # è·å–æ‰€æœ‰å¯ç”¨çš„ Strands å·¥å…·
        print("\nğŸ“¦ è·å–æ‰€æœ‰ Strands å·¥å…·...")
        tools = await tool_provider.get_tools_for_agent(
            include_legacy=False,
            include_mcp=False,
            include_strands=True
        )
        
        print(f"âœ… æˆåŠŸè·å– {len(tools)} ä¸ªå·¥å…·")
        
        # åˆ›å»ºå…¨èƒ½ Agent
        print("\nğŸ¤– åˆ›å»ºå…¨èƒ½ Agent...")
        super_agent = Agent(
            system_prompt="""You are a versatile AI assistant with access to various tools.
            You can:
            - Get current time information
            - Perform calculations
            - Make HTTP requests
            - Generate images (if available)
            - Generate speech (if available)
            
            Use the appropriate tools to complete user requests step by step.""",
            tools=tools
        )
        print("âœ… å…¨èƒ½ Agent åˆ›å»ºæˆåŠŸ")
        
        # å¤æ‚ä»»åŠ¡æµ‹è¯•
        print("\nğŸ¯ æ‰§è¡Œå¤æ‚ä»»åŠ¡...")
        complex_task = """Please help me with the following tasks:
        1. Tell me what time it is now
        2. Calculate how many seconds are in a day (24 * 60 * 60)
        3. Make a request to https://httpbin.org/status/200 to check if it's working
        
        Complete each task using the appropriate tools and provide a summary."""
        
        try:
            response = super_agent(complex_task)
            print(f"ğŸ¯ å¤æ‚ä»»åŠ¡å“åº”: {response}")
        except Exception as e:
            print(f"âŒ å¤æ‚ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
        
        print("\nğŸ‰ å¤æ‚ä»»åŠ¡æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ å¤æ‚ä»»åŠ¡æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 60)
    print("ğŸ§ª Strands Tools ç›´æ¥ LLM è°ƒç”¨æµ‹è¯•")
    print("=" * 60)
    
    # æ£€æŸ¥ç¯å¢ƒ
    print("\nğŸ” æ£€æŸ¥ç¯å¢ƒé…ç½®...")
    
    # æ£€æŸ¥ AWS å‡­è¯
    aws_configured = (
        os.getenv('AWS_ACCESS_KEY_ID') or 
        os.getenv('AWS_PROFILE') or 
        os.path.exists(os.path.expanduser('~/.aws/credentials'))
    )
    
    if not aws_configured:
        print("âš ï¸ è­¦å‘Š: æœªæ£€æµ‹åˆ° AWS å‡­è¯é…ç½®")
        print("   æŸäº›åŠŸèƒ½å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
    else:
        print("âœ… AWS å‡­è¯é…ç½®æ£€æµ‹æ­£å¸¸")
    
    # è¿è¡Œæ ¸å¿ƒæµ‹è¯•
    await test_llm_with_strands_tools()
    
    print("\n" + "=" * 60)
    print("ğŸ æµ‹è¯•å®Œæˆï¼")
    print("=" * 60)


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    asyncio.run(main())
